# ğŸš€ Logical Replication Controller for PostgreSQL (PG-ReplicaCtl)

### A Config-Driven Logical Replication Controller for PostgreSQL

PG-ReplicaCtl is a **declarative, idempotent control plane** for managing **PostgreSQL Logical Replication**.

It automates the *entire lifecycle* of logical replication using a **single configuration file**, safely reconciling PostgreSQLâ€™s current state with a desired state â€” without restarts, manual cleanup, or fragile scripts.

This project is intentionally designed to reflect **real production behavior**, not a toy example.

---

## ğŸ“Œ Why This Project Exists

PostgreSQL logical replication is powerful but operationally fragile:

- Strict prerequisites (`wal_level`, slots, workers)
- Schema must already exist on the target
- Slot behavior differs by topology
- Re-running scripts often leads to:
  - duplicate replication slots
  - WAL bloat
  - broken subscriptions
  - partial setups

**PG-ReplicaCtl solves this by acting as a reconciliation engine.**

> **Config = Desired State**  
> **PostgreSQL = Current State**  
> **Controller = Reconciler**

You can safely re-run it any number of times.

---

## âœ¨ What PG-ReplicaCtl Does

âœ… Validates PostgreSQL logical replication prerequisites  
âœ… Ensures databases exist  
âœ… Verifies schema compatibility (source vs target)  
âœ… Creates and updates publications  
âœ… Creates and reconciles subscriptions  
âœ… Correctly handles replication slots  
âœ… Supports incremental table additions  
âœ… Tracks applied state for idempotency  

---

## âŒ What PG-ReplicaCtl Does NOT Do

- âŒ Does not create schemas or tables
- âŒ Does not migrate DDL
- âŒ Does not manage application traffic
- âŒ Does not replace CDC platforms like Debezium

This tool focuses **only** on logical replication orchestration.

---

## ğŸ§  Core Design Principles

- Databases are **long-running infrastructure**
- Configuration is the **single source of truth**
- Safe to run **multiple times**
- Only **new changes** are applied
- Nothing is blindly recreated
- Same behavior locally and on AWS RDS

---

## ğŸ— Supported Replication Topologies

### 1ï¸âƒ£ Cross-Instance / Cross-Container Replication

```

Postgres A (sales) â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Postgres B (sales_replica)

```

- Replication slot is auto-created
- Subscription uses `create_slot = true`
- Standard PostgreSQL logical replication flow

---

### 2ï¸âƒ£ Same PostgreSQL Instance, Different Databases


```

Postgres Instance
â”œâ”€â”€ hr
â””â”€â”€ hr_replica

```

- Replication slot must be **manually created**
- Subscription uses `create_slot = false`
- Prevents slot conflicts and recursive replication
- Required for real PostgreSQL and AWS RDS setups

PG-ReplicaCtl detects this topology and handles it correctly.

---

## âš™ï¸ How the Controller Works (Step by Step)

For each replication defined in the config file:

1. **Precheck Engine**
   - PostgreSQL connectivity
   - Logical replication settings
   - Database existence

2. **Schema Validator**
   - Tables exist on source and target
   - Column order, types, and nullability match

3. **Publication Reconciliation**
   - Create publication if missing
   - Add only newly configured tables

4. **Replication Slot Handling**
   - Cross-instance: managed by subscription
   - Same-instance: explicitly created

5. **Subscription Reconciliation**
   - Create subscription if missing
   - Skip if already present

6. **State Persistence**
   - Applied state is stored
   - Enables safe, repeatable runs

---

## ğŸ“ Project Structure

```

logical-replication-controller/
â”‚
â”œâ”€â”€ docker-compose.yml # PostgreSQL + controller setup
â”œâ”€â”€ Dockerfile # Controller image
â”œâ”€â”€ replication_config.yaml # Desired replication state
â”œâ”€â”€ .lr_state.json # Controller-managed state file
â”‚
â”œâ”€â”€ main.py # Orchestration entry point
â”œâ”€â”€ config_loader.py
â”œâ”€â”€ state_store.py
â”œâ”€â”€ db.py
â”‚
â”œâ”€â”€ precheck/
â”‚ â””â”€â”€ engine.py # Precheck engine
â”‚
â”œâ”€â”€ schema/
â”‚ â””â”€â”€ validator.py # Schema validation logic
â”‚
â”œâ”€â”€ replication/
â”‚ â”œâ”€â”€ publication.py # Publication reconciler
â”‚ â”œâ”€â”€ subscription.py # Subscription reconciler
â”‚ â””â”€â”€ slot.py # Replication slot manager
â”‚
â””â”€â”€ README.md


```



---

## ğŸ“„ Configuration File (Desired State)

All behavior is driven by **one YAML file**.

Example:

```yaml
global:
  state_file: ".lr_state.json"

replications:
  sales_lr:
    source:
      host: source-db
      port: 5432
      database: sales
      user: repl_user
      password: repl_password

    target:
      host: target-db
      port: 5432
      database: sales_replica
      user: repl_user
      password: repl_password

    publication:
      name: sales_pub

    subscription:
      name: sales_sub
      copy_data: true

    tables:
      - public.orders
      - public.customers
```



## ğŸ” Incremental Workflow (No Restart Required)

To add a new table to replication:

1. Create the table in the **source** database  
2. Create the table in the **target** database  
3. Add the table to `replication_config.yaml`  
4. Re-run the controller  

âœ” No database restart  
âœ” No publication recreation  
âœ” No subscription recreation  

Only the **new table** is applied.

---

## ğŸ³ Local Development with Docker

PostgreSQL containers are treated as **long-running infrastructure** and run continuously.

### Start PostgreSQL (One Time)

```bash
docker compose up -d --build
```

Run the Controller


```
docker compose run --rm lr-tool

```





## ğŸ” Security Notes

- Passwords are inline only for local testing
- For real environments:
  - Use environment variables
  - Use AWS Secrets Manager or HashiCorp Vault
- PostgreSQL passwords cannot be retrieved from the database

## âš ï¸ Important PostgreSQL Facts

- Logical replication does not replicate schema
- Target tables must exist beforehand
- Replication slots are cluster-wide
- Improper slot cleanup causes WAL retention issues

PG-ReplicaCtl handles these constraints intentionally.
